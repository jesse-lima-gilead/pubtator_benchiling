{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "211022ca-14a8-415f-b8b7-eade5bbc5464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# S3 Bucket Explorer\n",
    "\n",
    "Lightweight S3 explorer using patterns from `src.pubtator_utils.file_handler.s3_handler`.\n",
    "\n",
    "**Bucket:** `gilead-edp-kite-rd-dev-us-west-2-kite-benchling-text-sql`  \n",
    "**Target Folder:** `benchling_unstructured/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd82cf5-b644-4f07-bd5b-33fea3b1267b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "S3IOUtil - Lightweight version mirroring src.pubtator_utils.file_handler.s3_io_util\n",
    "Works without YAML config, suitable for Databricks with direct S3 access.\n",
    "\"\"\"\n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "class S3IOUtil:\n",
    "    \"\"\"Lightweight S3 utility class (mirrors project's S3IOUtil without YAML dependencies).\"\"\"\n",
    "    \n",
    "    def __init__(self, bucket_name: str, bucket_region: str = \"us-west-2\"):\n",
    "        self.bucket_name = bucket_name\n",
    "        self.bucket_region = bucket_region\n",
    "        self.s3 = boto3.resource(\"s3\", region_name=bucket_region)\n",
    "        self.bucket = self.s3.Bucket(bucket_name)\n",
    "        self.client = boto3.client(\"s3\", region_name=bucket_region)\n",
    "    \n",
    "    def list_files(self, prefix: str = \"\") -> list:\n",
    "        \"\"\"List all files under a prefix (mirrors project's list_files).\"\"\"\n",
    "        files = []\n",
    "        for obj in self.bucket.objects.filter(Prefix=prefix):\n",
    "            if not obj.key.endswith(\"/\"):\n",
    "                files.append(obj.key)\n",
    "        print(f\"Found {len(files)} files under '{prefix}'\")\n",
    "        return files\n",
    "    \n",
    "    def download_file(self, object_name: str, file_path: str = None, as_binary: bool = False):\n",
    "        \"\"\"Download a file from S3 (mirrors project's download_file).\"\"\"\n",
    "        try:\n",
    "            obj = self.bucket.Object(object_name)\n",
    "            response = obj.get()\n",
    "            if file_path:\n",
    "                os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(response[\"Body\"].read())\n",
    "                return True\n",
    "            elif as_binary:\n",
    "                return response[\"Body\"].read()\n",
    "            else:\n",
    "                return response[\"Body\"].read().decode(\"utf-8\")\n",
    "        except ClientError as e:\n",
    "            print(f\"Error downloading {object_name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def file_exists(self, object_name: str) -> bool:\n",
    "        \"\"\"Check if a file exists (mirrors project's file_exists).\"\"\"\n",
    "        try:\n",
    "            self.client.head_object(Bucket=self.bucket_name, Key=object_name)\n",
    "            return True\n",
    "        except ClientError:\n",
    "            return False\n",
    "\n",
    "# Initialize\n",
    "BUCKET_NAME = \"gilead-edp-kite-rd-dev-us-west-2-kite-benchling-text-sql\"\n",
    "s3_util = S3IOUtil(BUCKET_NAME)\n",
    "print(f\"‚úÖ Connected to bucket: {BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3751e6e0-7559-406c-b824-7413e116c1d2",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"file\":543},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1768428482006}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List benchling_unstructured/ folder content\n",
    "PREFIX = \"benchling_unstructured/RD_Biovia_ELNs/\"\n",
    "\n",
    "files = s3_util.list_files(PREFIX)\n",
    "files = [f for f in files if f.lower().endswith('.pdf')]\n",
    "\n",
    "# Display as DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "def format_size(size_bytes: int) -> str:\n",
    "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
    "        if size_bytes < 1024:\n",
    "            return f\"{size_bytes:.1f} {unit}\"\n",
    "        size_bytes /= 1024\n",
    "    return f\"{size_bytes:.1f} TB\"\n",
    "\n",
    "# Get file details\n",
    "file_data = []\n",
    "for key in files[0:3]:\n",
    "    obj = s3_util.bucket.Object(key)\n",
    "    file_data.append({\n",
    "        \"file\": key.replace(PREFIX, \"\"),\n",
    "        \"size\": format_size(obj.content_length),\n",
    "        \"last_modified\": obj.last_modified.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "    })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(file_data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de399cc-0d1b-4a45-b5b7-83fbd3f85fb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze folder structure within benchling_unstructured/\n",
    "from collections import Counter\n",
    "\n",
    "subfolders = Counter()\n",
    "extensions = Counter()\n",
    "\n",
    "for key in files:\n",
    "    rel_path = key.replace(PREFIX, \"\")\n",
    "    parts = rel_path.split(\"/\")\n",
    "    \n",
    "    # Count subfolders\n",
    "    if len(parts) > 1:\n",
    "        subfolders[parts[0]] += 1\n",
    "    \n",
    "    # Count extensions\n",
    "    if \".\" in parts[-1]:\n",
    "        ext = \".\" + parts[-1].split(\".\")[-1].lower()\n",
    "        extensions[ext] += 1\n",
    "\n",
    "print(f\"üìÅ Subfolders in {PREFIX}:\")\n",
    "for folder, count in subfolders.most_common():\n",
    "    print(f\"   {folder}/: {count} files\")\n",
    "\n",
    "print(f\"\\nüìÑ File types:\")\n",
    "for ext, count in extensions.most_common():\n",
    "    print(f\"   {ext}: {count} files\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "s3_bucket_explorer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
