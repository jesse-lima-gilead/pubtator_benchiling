{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "741eb2d9-f359-4a70-afb6-8055eef059dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# S3 Bucket Explorer (Using Pubtator's S3IOUtil)\n",
    "\n",
    "This notebook uses Pubtator's `S3IOUtil` class directly, with YAML config injected inline.\n",
    "\n",
    "**Bucket:** `gilead-edp-kite-rd-dev-us-west-2-kite-benchling-text-sql`  \n",
    "**Target Folder:** `benchling_unstructured/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1df85c1-0a3e-477a-b897-c3c35f2faf05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# ============================================================\n",
    "# INLINE YAML CONFIG (replaces configs/aws.yaml)\n",
    "# ============================================================\n",
    "AWS_CONFIG = {\n",
    "    \"aws\": {\n",
    "        \"platform_type\": \"databricks\",\n",
    "        \"databricks\": {\n",
    "            \"s3\": {\n",
    "                \"bucket_name\": \"gilead-edp-kite-rd-dev-us-west-2-kite-benchling-text-sql\",\n",
    "                \"bucket_region\": \"us-west-2\",\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# Mock YAMLConfigLoader before importing S3IOUtil\n",
    "# ============================================================\n",
    "class MockYAMLConfigLoader:\n",
    "    \"\"\"Mock config loader that returns inline config instead of reading YAML files.\"\"\"\n",
    "    _instance = None\n",
    "    \n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super().__new__(cls)\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self, config_dir=None):\n",
    "        pass\n",
    "    \n",
    "    def get_config(self, name: str):\n",
    "        if name == \"aws\":\n",
    "            return AWS_CONFIG\n",
    "        return {}\n",
    "\n",
    "# Patch the config loader in the module before import\n",
    "import src.pubtator_utils.config_handler.config_reader as config_reader_module\n",
    "config_reader_module.YAMLConfigLoader = MockYAMLConfigLoader\n",
    "\n",
    "# Also patch in s3_io_util module\n",
    "import src.pubtator_utils.file_handler.s3_io_util as s3_io_util_module\n",
    "s3_io_util_module.config_loader = MockYAMLConfigLoader()\n",
    "\n",
    "print(\"‚úÖ Inline config injected successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "410fddd5-d630-41cf-b10d-4188d8f4910a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import Pubtator's S3IOUtil (now using our inline config)\n",
    "from src.pubtator_utils.file_handler.s3_io_util import S3IOUtil\n",
    "\n",
    "# Initialize with platform_type matching our config\n",
    "s3_util = S3IOUtil(platform_type=\"databricks\")\n",
    "\n",
    "print(f\"‚úÖ Connected to bucket: {s3_util.bucket_name}\")\n",
    "print(f\"   Region: {s3_util.bucket_region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a3a549f-0c17-46d7-a9b1-6e650304cec1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List benchling_unstructured/ folder using Pubtator's list_files method\n",
    "PREFIX = \"benchling_unstructured/RD_Biovia_ELNs/\"\n",
    "\n",
    "files = s3_util.list_files(prefix=PREFIX)\n",
    "files = [f for f in files if f.lower().endswith('.pdf')][0:3] # Filter PDFs\n",
    "\n",
    "print(f\"\\nüìÅ Files in '{PREFIX}':\")\n",
    "for f in files:  # Show first 20\n",
    "    print(f\"   {f}\")\n",
    "\n",
    "if len(files) > 3:\n",
    "    print(f\"   ... and {len(files) - 3} more files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa5ed1b0-f23a-4f82-b247-4b039a38806a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display as DataFrame with file details\n",
    "import pandas as pd\n",
    "\n",
    "def format_size(size_bytes: int) -> str:\n",
    "    for unit in ['B', 'KB', 'MB', 'GB']:\n",
    "        if size_bytes < 1024:\n",
    "            return f\"{size_bytes:.1f} {unit}\"\n",
    "        size_bytes /= 1024\n",
    "    return f\"{size_bytes:.1f} TB\"\n",
    "\n",
    "file_data = []\n",
    "for key in files:\n",
    "    obj = s3_util.bucket.Object(key)\n",
    "    file_data.append({\n",
    "        \"file\": key.replace(PREFIX, \"\"),\n",
    "        \"size\": format_size(obj.content_length),\n",
    "        \"last_modified\": obj.last_modified.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(file_data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acf10297-0d5d-491d-be8b-830c30d6024d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze folder structure\n",
    "from collections import Counter\n",
    "\n",
    "subfolders = Counter()\n",
    "extensions = Counter()\n",
    "\n",
    "for key in files:\n",
    "    rel_path = key.replace(PREFIX, \"\")\n",
    "    parts = rel_path.split(\"/\")\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        subfolders[parts[0]] += 1\n",
    "    \n",
    "    if \".\" in parts[-1]:\n",
    "        ext = \".\" + parts[-1].split(\".\")[-1].lower()\n",
    "        extensions[ext] += 1\n",
    "\n",
    "print(f\"üìÅ Subfolders in {PREFIX}:\")\n",
    "for folder, count in subfolders.most_common():\n",
    "    print(f\"   {folder}/: {count} files\")\n",
    "\n",
    "print(f\"\\nüìÑ File types:\")\n",
    "for ext, count in extensions.most_common():\n",
    "    print(f\"   {ext}: {count} files\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "s3_explorer_pubtator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
