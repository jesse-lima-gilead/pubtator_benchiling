{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T18:10:30.334994Z",
     "start_time": "2024-11-10T18:10:30.332265Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"hello\")",
   "id": "5e92ec1ffee849d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T18:11:03.928014Z",
     "start_time": "2024-11-10T18:10:36.746710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer from Hugging Face\n",
    "model_name = \"distilgpt2\"  # You can change this to another free model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "def generate_table_titles_and_descriptions(table_names):\n",
    "    results = []\n",
    "    for table_name in table_names:\n",
    "        # Construct the prompt for each table name\n",
    "        prompt = (\n",
    "            f\"Given the database table name '{table_name}', \"\n",
    "            \"provide a short, descriptive title for this table and a separate, detailed description of what the table likely contains.\\n\"\n",
    "            \"Title:\\n\"\n",
    "            \"Description:\"\n",
    "        )\n",
    "        \n",
    "        # Encode the input and generate a response\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=100,\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=2,\n",
    "            temperature=0.7,\n",
    "            top_k=50,\n",
    "            top_p=0.9\n",
    "        )\n",
    "        \n",
    "        # Decode the output and parse for title and description\n",
    "        response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        response_text = response_text[len(prompt):].strip()  # Remove the prompt from the response\n",
    "        lines = response_text.split('\\n')\n",
    "        \n",
    "        # Initialize title and description as empty\n",
    "        title = \"\"\n",
    "        description = \"\"\n",
    "        \n",
    "        # Extract the title and description\n",
    "        for line in lines:\n",
    "            if line.startswith(\"Title:\"):\n",
    "                title = line[len(\"Title:\"):].strip()\n",
    "            elif line.startswith(\"Description:\"):\n",
    "                description = line[len(\"Description:\"):].strip()\n",
    "        \n",
    "        # Append the results as a dictionary\n",
    "        results.append({\n",
    "            \"Table Name\": table_name,\n",
    "            \"Table Title\": title,\n",
    "            \"Table Description\": description\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "table_names = [\n",
    "    \"HARLAND_NONPROFIT_HEALTHCARE_AC\",\n",
    "    \"WMMSC_MODIFICATION_STG_ACZ\",\n",
    "    \"WAMU_PNC_MASTER_REC_C_ACZ\",\n",
    "    \"WAMU_PNC_MASTER_REC_A_ACZ\"\n",
    "]"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5b3f661680f4458adb60c4838277b33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78c2f1033c8940a5ad8abc77c62fb486"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00e0c9745dc848b7a0e47b5cf77905bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bc226b8f49b4050bbd6a656192cfceb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee8fba10dd574241a2130ffc7a1d8e23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32ccaae2557a456bacc951f3bf5d4078"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "075024f08f37444bab20f1c8ecf60960"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T18:11:22.406425Z",
     "start_time": "2024-11-10T18:11:18.988023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "table_info = generate_table_titles_and_descriptions(table_names)\n",
    "\n",
    "# Print the results\n",
    "for info in table_info:\n",
    "    print(f\"Table Name: {info['Table Name']}\\nTitle: {info['Table Title']}\\nDescription: {info['Table Description']}\\n\")"
   ],
   "id": "73e86e08b44d380f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaanbhatnagar/Library/Caches/pypoetry/virtualenvs/gileadpubtator-XugtBIpc-py3.12/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/Users/ishaanbhatnagar/Library/Caches/pypoetry/virtualenvs/gileadpubtator-XugtBIpc-py3.12/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Name: HARLAND_NONPROFIT_HEALTHCARE_AC\n",
      "Title: \n",
      "Description: \n",
      "\n",
      "Table Name: WMMSC_MODIFICATION_STG_ACZ\n",
      "Title: \n",
      "Description: \n",
      "\n",
      "Table Name: WAMU_PNC_MASTER_REC_C_ACZ\n",
      "Title: \n",
      "Description: \n",
      "\n",
      "Table Name: WAMU_PNC_MASTER_REC_A_ACZ\n",
      "Title: \n",
      "Description: \n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e1c2c1695278b611"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
